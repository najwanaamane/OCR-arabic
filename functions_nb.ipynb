{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abaf2bd1",
   "metadata": {},
   "source": [
    "## Importing Libraries and Setting Environment Variables\n",
    "\n",
    "In this cell, we import necessary libraries and set environment variables for TensorFlow and Keras. The imported libraries include:\n",
    "- `numpy` and `matplotlib` for numerical operations and plotting.\n",
    "- `os` for handling environment variables.\n",
    "- `cv2` and `PIL` for image processing.\n",
    "- `tensorflow.keras` for building and training the neural network model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a66ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and set environment variables for TensorFlow and Keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import RandomState\n",
    "import os\n",
    "\n",
    "# Ensure correct GPU order for TensorFlow\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "# Additional libraries for file handling, image processing, and machine learning\n",
    "import string\n",
    "from shutil import copyfile, rmtree\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import glob\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10d05c",
   "metadata": {},
   "source": [
    "## Global Variables and Helper Functions\n",
    "\n",
    "This cell defines a global variable for the ground truth data path and several helper functions for processing text data:\n",
    "- `get_Word(name)`: Extracts a word from a ground truth file.\n",
    "- `evaluate_word(name)`: Processes the word extracted by `get_Word` by replacing certain characters.\n",
    "- `get_lexicon_2(names)`: Generates a list of unique labels from a list of file names.\n",
    "- `get_lengths(names)`: Creates a dictionary mapping file names to the length of the words they contain.\n",
    "- `open_image(name, img_size=[100, 300])`: Opens and processes an image file, resizing and thresholding it, and retrieves the associated word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e277c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sets = ['set_a','set_b','set_c' ]\n",
    "\n",
    "def get_Word(name):\n",
    "    file_name = name.split(\"/\")[-1].split(\".\")[0]\n",
    "    load_profile = open('/'.join(name.split('/')[:len(name.split('/'))-2]) + \"/tru/\" + file_name + \".tru\", \"r\",encoding=\"latin-1\")\n",
    "    label = load_profile.read().splitlines()[6]\n",
    "    word = re.search(r\"AW2:(.*?);\", label).group(1).split('|')[:-1]\n",
    "    return word\n",
    "\n",
    "def evaluate_word(name):\n",
    "    word = get_Word(name)\n",
    "    for i, car in enumerate(word):\n",
    "        if car[-1] == \"1\" or car[-1] == \"2\":\n",
    "            word[i] = \"-\"\n",
    "    return word\n",
    "\n",
    "def get_lexicon_2(names):\n",
    "    arabic_labels = []\n",
    "    for name in names:\n",
    "        arabic_labels = arabic_labels + evaluate_word(name)\n",
    "    return list(dict.fromkeys(arabic_labels))\n",
    "\n",
    "def get_lengths(names):\n",
    "    d = {}\n",
    "    for name in names:\n",
    "        file_name = name.split(\"/\")[-1].split(\".\")[0]\n",
    "        word = get_Word(name)\n",
    "        d[file_name] = len(word)\n",
    "    return d\n",
    "\n",
    "def open_image(name, img_size=[100, 300]):\n",
    "    img = cv2.imread(name, 0)\n",
    "    img = cv2.resize(img, (img_size[1], img_size[0]), Image.LANCZOS)\n",
    "    img = cv2.threshold(img, 255 // 2, 255, cv2.THRESH_BINARY)[1]\n",
    "    img = cv2.bitwise_not(img)\n",
    "    word = get_Word(name)\n",
    "    return img, word\n",
    "\n",
    "class Readf:\n",
    "    def __init__(self, img_size=(100, 300), max_len=17, normed=False, batch_size=64, classes={}, mean=118.2423, std=36.72):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.normed = normed\n",
    "        self.classes = classes\n",
    "        self.max_len = max_len\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.voc = list(self.classes.keys())\n",
    "        if type(classes) == dict:\n",
    "            self.blank = classes[\"-\"]\n",
    "   \n",
    "    def make_target(self, text):\n",
    "        return np.array([self.classes[char] if char in self.voc else self.classes['-'] for char in text])\n",
    "\n",
    "    def get_labels(self, names):\n",
    "        Y_data = np.full([len(names), self.max_len], self.blank)\n",
    "        for i, name in enumerate(names):\n",
    "            img, word = open_image(name, self.img_size)\n",
    "            word = self.make_target(word)\n",
    "            Y_data[i, 0:len(word)] = word\n",
    "        return Y_data\n",
    "\n",
    "    def get_blank_matrices(self):\n",
    "        shape = (self.batch_size,) + self.img_size\n",
    "        X_data = np.empty(shape)\n",
    "        Y_data = np.full([self.batch_size, self.max_len], self.blank)\n",
    "        input_length = np.ones((self.batch_size, 1))\n",
    "        label_length = np.zeros((self.batch_size, 1))\n",
    "        return X_data, Y_data, input_length, label_length\n",
    "\n",
    "    def run_generator(self, names, downsample_factor=2):\n",
    "        n_instances = len(names)\n",
    "        N = n_instances // self.batch_size\n",
    "        rem = n_instances % self.batch_size\n",
    "\n",
    "        while True:\n",
    "            X_data, Y_data, input_length, label_length = self.get_blank_matrices()\n",
    "            i, n = 0, 0\n",
    "            for name in names:\n",
    "                img, word = open_image(name, self.img_size)\n",
    "                word = self.make_target(word)\n",
    "                if len(word) == 0:\n",
    "                    continue\n",
    "                Y_data[i, 0:len(word)] = word\n",
    "                label_length[i] = len(word)\n",
    "                input_length[i] = (self.img_size[0] + 4) // downsample_factor - 2\n",
    "                X_data[i] = img[np.newaxis, :, :]\n",
    "                i += 1\n",
    "                if i == self.batch_size:\n",
    "                    n += 1\n",
    "                    inputs = {\n",
    "                        'the_input': X_data,\n",
    "                        'the_labels': Y_data,\n",
    "                        'input_length': input_length,\n",
    "                        'label_length': label_length,\n",
    "                    }\n",
    "                    outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "                    yield (inputs, outputs)\n",
    "                    X_data, Y_data, input_length, label_length = self.get_blank_matrices()\n",
    "                    i = 0\n",
    "            if rem > 0:\n",
    "                inputs = {\n",
    "                    'the_input': X_data[:rem],\n",
    "                    'the_labels': Y_data[:rem],\n",
    "                    'input_length': input_length[:rem],\n",
    "                    'label_length': label_length[:rem],\n",
    "                }\n",
    "                outputs = {'ctc': np.zeros([rem])}\n",
    "                yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61795691",
   "metadata": {},
   "source": [
    "## Data Reading and Preprocessing Class\n",
    "\n",
    "This cell defines the `Readf` class, which is responsible for reading and preprocessing image and text data. The class constructor (`__init__`) initializes various parameters such as image size, batch size, normalization parameters, and class labels. \n",
    "\n",
    "`make_target`: Converts text into a numerical array using the classes dictionary.   \n",
    "`get_labels`: Creates a label matrix for given file names.   \n",
    "`get_blank_matrices`: Initializes blank matrices for input data, labels, input lengths, and label lengths.   \n",
    "`get_label_from_path`: Extracts the label from the file path.   \n",
    "`run_generator`: Generator function to yield batches of data for training.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89920d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Readf:\n",
    "    def __init__(self, img_size=(100, 300), max_len=17, normed=False, batch_size=64, classes={}, mean=118.2423, std=36.72):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.normed = normed\n",
    "        self.classes = classes\n",
    "        self.max_len = max_len\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.voc = list(self.classes.keys())\n",
    "\n",
    "        if type(classes) == dict:\n",
    "            self.blank = classes[\"-\"]\n",
    "\n",
    "    def make_target(self, text):\n",
    "        return np.array([self.classes[char] if char in self.voc else self.classes['-'] for char in text])\n",
    "\n",
    "    def get_labels(self, names):\n",
    "        Y_data = np.full([len(names), self.max_len], self.blank)\n",
    "        for i, name in enumerate(names):\n",
    "            img, word = open_image(name, self.img_size)\n",
    "            word = self.make_target(word)\n",
    "            Y_data[i, 0:len(word)] = word\n",
    "        return Y_data\n",
    "\n",
    "    def get_blank_matrices(self):\n",
    "        shape = (self.batch_size,) + self.img_size\n",
    "        X_data = np.empty(shape)\n",
    "        Y_data = np.full([self.batch_size, self.max_len], self.blank)\n",
    "        input_length = np.ones((self.batch_size, 1))\n",
    "        label_length = np.zeros((self.batch_size, 1))\n",
    "        return X_data, Y_data, input_length, label_length\n",
    "\n",
    "    def get_label_from_path(self, img_path):\n",
    "        # Example function to extract label from file path\n",
    "        # You need to modify this according to how your labels are stored or derived\n",
    "        file_name = os.path.basename(img_path)\n",
    "        label_text = file_name.split('_')[0]  # Assuming the label is part of the file name\n",
    "        \n",
    "        # Convert label text to class indices, handle characters not in self.classes\n",
    "        label = []\n",
    "        for char in label_text:\n",
    "            if char in self.classes:\n",
    "                label.append(self.classes[char])\n",
    "            else:\n",
    "                print(f\"Warning: Character '{char}' not found in classes.\")\n",
    "                label.append(self.blank)  # Append blank class or handle as needed\n",
    "\n",
    "        return label\n",
    "\n",
    "    def run_generator(self, names, downsample_factor=2):\n",
    "        n_instances = len(names)\n",
    "        N = n_instances // self.batch_size\n",
    "        rem = n_instances % self.batch_size\n",
    "    \n",
    "        while True:\n",
    "            X_data, Y_data, input_length, label_length = self.get_blank_matrices()\n",
    "    \n",
    "            i, n = 0, 0\n",
    "    \n",
    "            for name in names:\n",
    "                img, word = open_image(name, self.img_size)\n",
    "                word = self.make_target(word)\n",
    "    \n",
    "                # Skip if word length is zero\n",
    "                if len(word) == 0:\n",
    "                    continue\n",
    "    \n",
    "                Y_data[i, 0:len(word)] = word\n",
    "                label_length[i] = len(word)\n",
    "                input_length[i] = (self.img_size[0] + 4) // downsample_factor - 2\n",
    "    \n",
    "                X_data[i] = img[np.newaxis, :, :]\n",
    "                i += 1\n",
    "    \n",
    "                if i == self.batch_size:\n",
    "                    n += 1\n",
    "                    inputs = {\n",
    "                        'the_input': X_data,\n",
    "                        'the_labels': Y_data,\n",
    "                        'input_length': input_length,\n",
    "                        'label_length': label_length,\n",
    "                    }\n",
    "                    outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "                    yield (inputs, outputs)\n",
    "    \n",
    "                    # Reset everything\n",
    "                    X_data, Y_data, input_length, label_length = self.get_blank_matrices()\n",
    "                    i = 0\n",
    "    \n",
    "            # Handle remaining instances\n",
    "            if rem > 0:\n",
    "                inputs = {\n",
    "                    'the_input': X_data[:rem],\n",
    "                    'the_labels': Y_data[:rem],\n",
    "                    'input_length': input_length[:rem],\n",
    "                    'label_length': label_length[:rem],\n",
    "                }\n",
    "                outputs = {'ctc': np.zeros([rem])}\n",
    "                yield (inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b1ca6",
   "metadata": {},
   "source": [
    "## CNN-LSTM Model Class\n",
    "\n",
    "This cell defines the `CRNN` class, which creates a model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory networks (LSTM). The class constructor (`__init__`) initializes various model parameters. The `create_model` method constructs the model architecture, including convolutional layers, reshaping layers, dense layers, bidirectional LSTM layers, and output layers. A custom Connectionist Temporal Classification (CTC) loss function is also defined to handle sequence prediction tasks.\n",
    "\n",
    "`class CRNN`: Defines a class to create a CNN-LSTM model for OCR.   \n",
    "`__init__`: Initializes the model parameters like image width, height, output size, maximum length, etc.   \n",
    "`ctc_lambda_func`: Defines a custom CTC loss function for sequence prediction tasks.   \n",
    "`create_model`: Creates the CNN-LSTM model.  \n",
    "Defines input data shape.   \n",
    "Adds convolutional layers with activation and pooling layers.   \n",
    "Adds a reshaping layer to prepare data for the RNN.   \n",
    "Adds dense and bidirectional LSTM layers.   \n",
    "Adds output layers with softmax activation.   \n",
    "Defines inputs for CTC loss and constructs the final model.   \n",
    "Prints the model summary.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008f031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN:\n",
    "    def __init__(self, img_w, img_h, output_size, max_len):\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.output_size = output_size\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Network parameters\n",
    "        self.conv_filters = 16\n",
    "        self.kernel_size = (3, 3)\n",
    "        self.pool_size = 2\n",
    "        self.time_dense_size = 32\n",
    "        self.rnn_size = 512\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def ctc_lambda_func(self, args):\n",
    "        y_pred, labels, input_length, label_length = args\n",
    "        #y_pred = y_pred[:, 2:, :]\n",
    "\n",
    "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input layer\n",
    "        input_data = Input(name='the_input', shape=(self.img_h ,self.img_w), dtype='float32')\n",
    "        \n",
    "        # Expand dimensions to include channel dimension\n",
    "        expanded_input = Lambda(lambda x: K.expand_dims(x, axis=-1))(input_data)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        conv_1 = Conv2D(self.conv_filters, self.kernel_size, padding='same', activation='relu', name='conv1')(expanded_input)\n",
    "        pool_1 = MaxPooling2D(pool_size=(self.pool_size, self.pool_size), name='pool1')(conv_1)\n",
    "        \n",
    "        conv_2 = Conv2D(self.conv_filters, self.kernel_size, padding='same', activation='relu', name='conv2')(pool_1)\n",
    "        pool_2 = MaxPooling2D(pool_size=(self.pool_size, self.pool_size), name='pool2')(conv_2)\n",
    "        \n",
    "\n",
    "        #Reshaping the outputs from a CNN to be the inputs of an RNN enables the integration of spatially encoded features with temporal dependencies for sequential data analysis\n",
    "        conv_to_rnn_dims = (self.img_w // (self.pool_size * 2), self.img_h // (self.pool_size * 2) * self.conv_filters)\n",
    "        reshaped = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(pool_2)\n",
    "        \n",
    "        # Dense layer\n",
    "        dense = Dense(self.time_dense_size, activation='relu', name='dense')(reshaped)\n",
    "        \n",
    "        # RNN layers\n",
    "        rnn = Bidirectional(LSTM(self.rnn_size, return_sequences=True), name='biLSTM')(dense)\n",
    "        \n",
    "        # Output layer\n",
    "        y_pred = Dense(self.output_size, activation='softmax', name='softmax')(rnn)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        labels = Input(name='the_labels', shape=[self.max_len], dtype='float32')\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "        \n",
    "        ctc_loss = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "        \n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=[ctc_loss, y_pred])\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004df4ed",
   "metadata": {},
   "source": [
    "## CTC Loss Explained in the CRNN Model\n",
    "\n",
    "The code above defines a custom CTC loss function (`ctc_lambda_func`) used within a CRNN model for Optical Character Recognition (OCR). Here's a breakdown of CTC and its role in this context:\n",
    "\n",
    "**Connectionist Temporal Classification (CTC):**\n",
    "\n",
    "* CTC is a loss function specifically designed for sequence labeling tasks, particularly those with variable-length outputs like OCR. \n",
    "* In OCR, the model predicts a sequence of characters for each image, and the length of the predicted sequence might differ from the actual text length.\n",
    "* CTC can handle these variable-length sequences by aligning the predicted characters with the ground truth (actual text) in an optimal way, even if insertions or deletions occur in the prediction. \n",
    "\n",
    "**How CTC Works:**\n",
    "\n",
    "* CTC considers all possible alignments between the predicted sequence and the ground truth.\n",
    "* It calculates a probability score for each alignment, considering the likelihood of each character prediction at each position.\n",
    "* The CTC loss function then computes the negative log-likelihood of the most probable alignment. \n",
    "\n",
    "**Implementation in the Code:**\n",
    "\n",
    "* The `ctc_lambda_func` defines the custom CTC loss function. \n",
    "* It takes four arguments:\n",
    "    * `y_pred`: The model's predicted probabilities for each character at each position in the sequence.\n",
    "    * `labels`: The ground truth labels (one-hot encoded) representing the actual characters.\n",
    "    * `input_length`: An array indicating the length of the input sequence (likely all set to the same value).\n",
    "    * `label_length`: An array indicating the length of the ground truth label sequence (may vary depending on the actual text length).\n",
    "* The function uses Keras' `K.ctc_batch_cost` function to calculate the CTC loss based on the provided arguments.\n",
    "\n",
    "**Benefits of CTC:**\n",
    "\n",
    "* CTC's ability to handle variable-length sequences makes it well-suited for OCR tasks.\n",
    "* It allows the model to learn even from partially incorrect predictions by considering all possible alignments.\n",
    "\n",
    "**Overall, the CTC loss function plays a crucial role in training the CRNN model. It helps the model learn to predict the most likely character sequences for the input images by penalizing deviations from the ground truth while accounting for potential variations in sequence lengths.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a61cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
